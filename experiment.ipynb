{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Mr-Patty/bimodal-emotion-recognition\n",
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp drive/'My Drive'/EmotionRecognition/bimodal-emotion-recognition.tar.gz bimodal-emotion-recognition/\n",
    "%cd bimodal-emotion-recognition\n",
    "!tar -C . -xzf bimodal-emotion-recognition.tar.gz\n",
    "!rm bimodal-emotion-recognition.tar.gz\n",
    "!mv Audio_ogg_10 Audio_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import math\n",
    "import librosa\n",
    "import json\n",
    "import wave\n",
    "import sys\n",
    "import pickle\n",
    "import sklearn\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "import librosa.display\n",
    "import scipy, matplotlib.pyplot as plt, IPython.display as ipd\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import os\n",
    "import matplotlib.style as ms\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from utils import *\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {'ang': 0,\n",
    "                'dis': 1,\n",
    "                'hap': 2,\n",
    "                'sad': 3,\n",
    "                'sca': 4,\n",
    "                'sur': 5,\n",
    "                'neu': 6\n",
    "                }\n",
    "labels_df = pd.read_csv('df_prep.csv').to_numpy()\n",
    "columns = ['wav_file', 'label', 'sig_mean', 'sig_std', 'rmse_mean', 'rmse_std', 'silence', 'harmonic', 'auto_corr_max', 'auto_corr_std']\n",
    "df_features = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, emo in tqdm(labels_df):\n",
    "    try:\n",
    "        wav_file_name = 'Audio_preprocess/' + file + '.ogg'\n",
    "        label = emotion_dict[emo]\n",
    "        y, _sr = librosa.load(wav_file_name, sr=48000)\n",
    "\n",
    "        feature_list = [wav_file_name, label]  # wav_file, label\n",
    "        sig_mean = np.mean(abs(y))\n",
    "        feature_list.append(sig_mean)  # sig_mean\n",
    "        feature_list.append(np.std(y))  # sig_std\n",
    "\n",
    "        rmse = librosa.feature.rms(y + 0.0001)[0]\n",
    "        feature_list.append(np.mean(rmse))  # rmse_mean\n",
    "        feature_list.append(np.std(rmse))  # rmse_std\n",
    "\n",
    "        silence = 0\n",
    "        for e in rmse:\n",
    "            if e <= 0.4 * np.mean(rmse):\n",
    "                silence += 1\n",
    "        silence /= float(len(rmse))\n",
    "        feature_list.append(silence)  # silence\n",
    "\n",
    "        y_harmonic = librosa.effects.hpss(y)[0]\n",
    "        feature_list.append(np.mean(y_harmonic) * 1000)  # harmonic (scaled by 1000)\n",
    "\n",
    "        # based on the pitch detection algorithm mentioned here:\n",
    "        # http://access.feld.cvut.cz/view.php?cisloclanku=2009060001\n",
    "        cl = 0.45 * sig_mean\n",
    "        center_clipped = []\n",
    "        for s in y:\n",
    "            if s >= cl:\n",
    "                center_clipped.append(s - cl)\n",
    "            elif s <= -cl:\n",
    "                center_clipped.append(s + cl)\n",
    "            elif np.abs(s) < cl:\n",
    "                center_clipped.append(0)\n",
    "        auto_corrs = librosa.core.autocorrelate(np.array(center_clipped))\n",
    "        feature_list.append(1000 * np.max(auto_corrs)/len(auto_corrs))  # auto_corr_max (scaled by 1000)\n",
    "        feature_list.append(np.std(auto_corrs))  # auto_corr_std\n",
    "\n",
    "        df_features = df_features.append(pd.DataFrame(feature_list, index=columns).transpose(), ignore_index=True)\n",
    "    except:\n",
    "        print('Some exception occured')\n",
    "        raise\n",
    "\n",
    "df_features.to_csv('audio_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()\n",
    "df_features[df_features.columns[2:]] = scalar.fit_transform(df_features[df_features.columns[2:]])\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = train_test_split(df_features, test_size=0.20)\n",
    "\n",
    "x_train.to_csv('audio_train.csv', index=False)\n",
    "x_test.to_csv('audio_test.csv', index=False)\n",
    "y_train = x_train['label']\n",
    "y_test = x_test['label']\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import itertools\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-40f04e27e8fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrf_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=1200, min_samples_split=25)\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Predict\n",
    "pred_probs = rf_classifier.predict_proba(x_test)\n",
    "\n",
    "# Results\n",
    "display_results(y_test, pred_probs)\n",
    "\n",
    "with open('rf_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(pred_probs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
